# Building Your Own ML Application with AWS Lambda and Amazon SageMaker

In this workshop, we will step through the process of deploying and hosting machine learning (ML) models with AWS Lambda and get on-demand inferences. 

Given a demonstrative dataset, we build and train a simple ML classification model with Amazon SageMaker. Then, we host this model in an AWS Lambda function and expose an inference endpoint through Amazon API Gateway. Finally, we build a pipeline for automating model deployment to Lambda leveraging AWS CodeBuild, AWS CodeDeploy, and AWS CodePipeline.

.. Add details on the spam filter use case + picture ..

## Prerequisites

.. Add prerequisites ..

### AWS Account
...

### AWS Region
...

### Browser
...

### AWS CLI
...

## Let's get started

Execute the following steps:

1. [Training the Spam Filter model with Amazon SageMaker](training/README.md)
2. [Hosting the model in a Lambda Function and executing inferences](hosting/README.md)
3. [Automating deployment](automating/README.md)

## License

The contents of this workshop are licensed under the [Apache 2.0 License](./LICENSE).
